Okay, so I guess the idea is floating in my head for this baseline MVP or that there's going to be this different sort of interaction with the agents. It's not a chatbot. It's not like you're texting someone; you have the back-and-forth there anymore. It's not like you're on that like ChatGPT or Claude or whatever, and you have a little artifact on the side that was generated and that you had explicitly asked for and that you can't really quickly update. Rather, this is going to be a far more interactive experience and a more stateful experience. It's going to be command-driven, UI-driven, and there's going to be persistence of information long-term as well as modular connections as a sort of idea there. Of course, we could specialize in the future. I see this being a very widely adopted pattern, but it can be modular. It can be it can cover a lot of ground, a lot of surface. Okay, so I'll just start yapping. This isn't exactly going to be like a coherent or like it's going to be useful information; it's not going to be very well structured, but all of it will be useful, and it'll communicate the vibe. So like, there could be a calendar model context protocol server. I know Google has a Google Calendar MCV server, and we could give the agentic system okay, and this is not only a single agent; it's like an agentic system. We can hook up a Google Calendar MCV, and then while we talk to it, okay, it can alter our calendar, and it doesn't necessarily have to show us the UI change; it doesn't have to present us the Google Calendar. We could do that, I guess. It'd be potentially much more involved or it's not standardized and sort of made easy by Google, but I mean, these days, honestly, if you're shipping millions of lines of code a day, then it's not necessarily that hard. There's complexity, but my point is, yeah, we can for example hook up a Google Calendar MCV, and then the agent can alter it. That's just like one thing you could do, and that's modular. You could just have it configured even within the session. You can configure other MCVs, you can configure other agents, and then the agentic system will realize this, and yeah, okay, they can be capable. Another interesting thing is the idea of using on-the-fly patterns like LLM as a judge on any sort of input or output. But let's define it granularly. Say you have a deep research job that was sent off. You can say, "Hey, you want a deep research job," and then you're like, "Okay, hey, I want to do an LLM as a judge, and I want to critique something about this deep research report," and you know, then you can get five different perspectives, and you could have a single LLM that can combine them in a way. That's like an example of inference time compute literally at the tip of your fingers. You're not sitting here in like ChatGPT with this unreliable horseshit right with the lack of control in the user interface right? You're literally sending off these tasks and you're doing it your way. You can throw more compute at it if that's what you wish right? And then even the result of that that can be for example persisted. Say you want that to be some sort of thing that you want to save and then reference later and like in the current session with the adjunct system, you want to continue talking about this right? And so you can continue doing work. Wow! Instead of like branching between chats and having multiple chats open getting different perspectives having a having a little Google Doc open hoping that ChatGPT actually alters the Google Doc for example right?
Another you know another useful thing right is that you could perhaps observe some state from sort of API end point maybe the agent could grab it from a server or something like this perhaps it's some single source of truth for something particular and then you can have this visual representation of this state right and so if you're if you if this is a copy of a single source of truth in your constantly pulling it or it's like a WebSocket or something then you could literally have this live dashboard of this state you know that that has tremendous usage literally like everywhere you know and you don't necessarily have to mutate it right you can just be observing it and it could be some use full dashboard and of course perhaps you could implement some integrations to alter the state right and then it could see the live state update if it's a single source of truth and even you end up altering it right so these can this this is exponential this goes to very dynamic and complex workflows that are achievable here and this is this is these are strides away from the regular you know the chatbot interface. This is more of an immersive you know command intent oriented like workspace right. Another you know and then another example of that would be so we have a like a task DAG, a task directed acyclic graph, and it has like granularities to display from the single source of truth right but yeah you're not you're not necessarily altering that state not necessarily taking input from you right. So yeah okay so another idea now it's like the agents or like s class you know like first class right citizens to the program you know the idea is that like I mean sure maybe you could have like some CRUD going on some basic functionality of some program but the idea is that the agent experience can augment the software so much such that we're going to be heavily relying on the agents to augment our experience right. Another note that was written down was like a self-modifying workflow. And so like I mean hey we can have like I'm sure they're going to be these catered systems that are not super super modular where they can do like everything under the sun right. You know there's obviously going to be some specification to some degree and I'm not going to say like all ways. I mean hell in the future it may be very general and on the fly who the hell knows right but regardless you know self-modifying would be nice to add that capability in. And for example we were talking about adding in the Google Calendar like mcp right. Like maybe there could be some baseline rules to the system to add a new mcp server and maybe they have to be set up in some particular environment and pass some security check and adhere to some specified standards right. But it could be self-modifying we could request like hey I want this mcp server and then it does it right as long as this mcp server adheres to standards okay. And so now we're talking about input into the system this is another thing that I wrote down um and so like we could just imagine like a text box right. And then like maybe you could drag files to it or something but it's not specifically attached to like this text message chatbot thing you know this is we just imagine a text box just sort of chilling somewhere on this canvas and that's just like a way to get context into this system so that it is systematically handled okay. So that's just one example like sure a text box hell you could be like a microphone icon maybe you just use Wispr Flow and you're getting it transcribed in a text or something like that huh maybe there's speech-to-speech with real-time tool calls or something like that okay. And then as well we can imagine like this text box maybe it's hovering over on top.
We could imagine the text box that's hovering over this canvas. What's the canvas? It's really just this place that is stateful, it can hold context, and it can be altered by the agentic system. It could be altered by you in some way if we program it to be such. We'll obviously have to define boundaries and stuff. The idea is that there's going to be a shared state going on there between the user and the agentic system, and that the state is going to be accessible. But it's not necessarily going to be utilized like 24/7, right? Like, on this canvas, for some reason you have 10 nodes open and they have labels, and maybe there are 5 documents. Right. And you're just in a sort of thinking workhorse session or something like that. You have audio blocks, for example, and you're sort of just flowing where things are. You've got your associative short-term memory, and you're just flowing, being productive. When you're talking about something, you're not going to reference all of this information at once, right? But the point is, it will be accessible to you, right? Accessible. And same to the agents. We know about context draw, we know about specificity with the tasks, right? It's important to have focus. We're going to get into the context routing concept, okay? But for now, we've only talked about the text boxes, this info, we've talked about the CRUD on a canvas, okay. Another example, this could be on the canvas itself. It could be like we have jobs, I don't know, just a concept, okay? We're just naming things. Like, say you have a job, it's like, "Hey, go do this deep research report," for example. And that's off doing whatever. Maybe we're getting like WebSocket streaming or some sort of state streaming to the UI. We're getting the updates that are like sort of felt by the user. Maybe the system's processing that context that's being received from that endpoint or whatever, right? And so, that could be context like and put to the system, just like the text box, just like the CRUD on the canvas from the user. That returned from the job and deep research report, like an artifact itself from just the streaming. That information, what the updates along the way, that's all context being given to the system. It has to be handled. And then, more deterministically, maybe if we're thinking about these like a bunch of workflows essentially this agentic system. Maybe like internally we can think of like input into the system itself. There are like deterministic hooks after specific life cycles or something like that. Another thing we could think of is like input to the system, some sort of user commands to configure a specific model context protocol server, or do something with agent agent protocol, right? So yeah, we would be handling that context, okay? And so, we're talking about handling context, right? And so, we have to get into the concept of like context routing, okay? What context routing is going to do for us is, well, we were talking about there's going to be a context router for just using a single agent, and sure, we have the harnesses to protect the contacts when they're etc, but I mean, frankly, yeah, if we're going to be able to have a useful system, yeah, we're going to have sort of these delegated modular areas. We've got to have something defined to have something done useful, right? So yeah, we can do the context routing, okay? And so, this is another blurb. The context itself may already have associations like structure, particular handling, some specific state, like the context returned from a job, oh okay, yeah, so like the deep research report, perhaps we've scheduled the report to have some sort of LLM that's a Judge Analysis, so yeah, same idea that was mentioned before.
Another thought on handling the input of context into the identity system. Okay, say the user inputs something into the text box. Then it's like, "What the hell is going to go on? How are we going to handle this information?" We have to define these things. The idea here that I've written down is to decipher the intent/meaning. Sure, the user said some shit, and we got to figure out what the hell they mean. We need to reach some sort of consensus and agree in agreeance so that we can actually be productive. Also written as utilizing a persisted user intent meaning index. There's this idea of memory, and the more a user interacts with a system, the more of a gauge that we can have on the user's behavior, the more that we can assume what the hell they mean or what intent they want. It's just intelligent routing, it's context routing, okay, but along with that, so I have AND. AND is like the unit, sure, like a particular agent or some sort of sub-system's own reasoning to make an assumption based off of the context. These damn things are smart, okay, so they can just sort of look at it, maybe one particular agent or some sort of agent composed of sub-agents, or even a dedicated workflow. I'm just going to look at this context and decipher, and so we have AND, and it says like, "AND available tools/capabilities," so that's three things. Let's start over. We have the input context into the Eugenic system, we have to decipher the intent/meaning, and yes, this input right now, at least in my head, we're just talking about a text field input or something, but obviously, there could be other types, say you're interacting with the canvas and doing CRUD on it or something. I mean, yeah, we can go a lot of different ways, but we've got to map them all. Just decipher, take the input text field, decipher the intent/meaning, and then:

1.  Utilize persistent user intent meaning index
2.  Use the agent/workflow/whatever's own reasoning to make some sort of assumptions/inference on what the hell we think that they mean
3.  Use our available tools as well in our inference, and we're also just inferring based off of that index that we're accessing as well, right?

We're talking about making an assumption of inference, whatever, okay? And there can be multiple parts if a lot of information was said, we have to decompose all this information. Ideally, we have a good system that's not going to sit here and lose information. We want to be granular, but not too, not redundant, right? And so, we can have this idea of like, we have assumptions, whatever, based on this input, and we can have some sort of container, some sort of state for like, assumptions based on that input. So, it's like, we send off this input, it gets processed, right, and then we have like, assumptions, based on the meaning/intent, and the meaning is just like, say we have an acronym, and we want to define the acronym explicitly, like, the user is sort of conveying they want some sort of action done on a canvas for example, or something that they wish they could do. They're sort of vague, they're not saying a particular tool that they know that the system has. We could sort of refer, "Hey, did we have the capabilities to make this happen," or, "Maybe they're saying something that we just don't have the capability to handle," like, maybe that we don't have the tooling, like MCP set up, whatever. You know, then you know, we would infer, in that case, you would say, "Hey, we don't have this capability, something like this," or, if this is a dev working with this in an alpha environment, then we know what the hell's sort of going on there.
And so like yeah we'll have like the sort of assumption structure okay and so we can imagine sending this information like into the textbox we press enter whatever and then uh you know we're doing the processing okay we're trying to infer make some assumptions reach some consensus okay we have these assumption structure and then we want to like reconcile or approve you know like with the user we want to you know have this sort of uh this understanding but on the meaning what the hell they want um and and so that that we need to have that aspect and that can be you know rendered on the ui and it can have its own like dedicated space for example like some sort of like assumption area on the screen uh you know i mean you can do whatever the hell you want with ui but and then you know how are they gonna respond to that maybe they type in the textbox and or maybe there are buttons associated with it right but either way we're going to reach this consensus and make progress okay and so uh with this base idea uh what this will immediately help me with is a few things that are written down so for one you know like uh say we're like we're in a session okay lots of ideas going on all right like what we've described is pretty high velocity pretty high throughput you know we and we need reliability you know and um and so you know one thing is like for random eureka you know like you know thoughts to the mind uh even in yeah you know like something that's you know maybe unrelated to the current focus of like the session you know maybe there's an overall theme that can be established right even with what i said earlier you know we can have like 10 nodes like five documents audio blocks something like that it doesn't all necessarily have to be related we're flowing we have our associated memory right our working memory only has so much capacity hey we're just flowing we can navigate around we can we can look at things we can uh sort of you know infer you know based on just the spatial associativity by looking at it you know we could talk with the system short jogger memory you know this is really augmenting processing ability okay but yeah uh you know the random eurekas you know we want to be able to get down our random ass notes add a little labeling maybe send off a damn deep research report maybe we have some sort of a useful analysis workflow that we can just throw with that thing maybe we have some predefined like associative sort of search throughout some sort of connected knowledge base and so there yeah we could send that ditch off there's a lot of things we could do you know we need the capability uh another one was uh you know uh help like analyzing thoughts you know and and so like say say we have a thought maybe it's a tangent you know long-winded whatever uh say I have an audio block and I'm just you know maybe on the canvas and I click like new like audio block or something I just have like a 30 minute spiel right uh and then you know maybe I want to have some back and forth with an agent on it maybe I want to do like multiple deep research reports that will go off and be sent based on this based on this tangent right at all from the damn canvas okay and maybe I want to apply some LLM uh like as judges on those deep research reports maybe in crafting them maybe just separately from the deep research reports and uh you know just getting uh some sort of like separate opinion maybe we're testing hypotheses you know maybe we're debating right we're just looking at it from a different sort of like semantics scopes right if that's what we want if that's what we define it to be the point is we have very high throughput you know we we have a lot of capability here that's the entire point uh and another one okay persisting information right we're doing all this work but obviously we wanted to be persistent right so that's just basic crud okay and obviously with the agents they can up you know they can delete so that this is this is an important thing to consider and then also it's like do we want a whole uh database for this or we or we just kind of run like Obsidian maybe use like Git repos for for backups you know and uh uh things like that those are things to consider uh another very important thing okay so we're going to want to command the system to generate visual representations and and alter them okay.
We're going to want to generate visual representations and be able to alter them. Right? Well, we're going to want to be able to command the system. We have high throughput here. Okay? So say you're bouncing around ideas and you just want to visualize things. Okay? So, you can take maybe there are some basic data structures like in Coda that have mappings to the UI. Right? Okay. And so you can say, "Hey, I'm in a spiel, right? I have to do a lot of context switching because I'm juggling 20 fucking different things at once. Right? So maybe I want to focus on 7 of those things right now and then I can have 7 different nodes and then properly labeled, okay? And then I can sort of just jump around as my thinking and so my work is augmenting my fucking working memory. That's exactly what I'm doing. Right? And so, what would be useful here? What is the next obvious fucking job? Well, like highly annotatable graphs, right? So we're talking about no just about relations potentially. Right? Well, let's add the fucking bullet points. Let's be able to interact with a graph. Maybe we have persisted information somewhere, connect knowledge base and you know, you have some sort of node and it's like app store optimization. Okay, and you have a dedicated document or dedicated folder or some dedicated sort of like workflow that links these two where maybe the system just infers the usefulness based on the context. You could for example, and you could command this, so I click the node and then the information is brought up and then you can further interact with the information with the agentic system, right? Another example, very important. You can both sort of like collaborate on a plan in the agentic system, collaborate on a plan, okay? And then you could get it and like the task tag for it, right? And so I say there's like a hackathon or something, okay? And you want to make a good fucking plan because you don't want to fucking lose. Right? This may involve the deep research LLM says judges for example, okay. Maybe you just have a bunch of ideas, right? But the thing is, we could form a structured, competitive, first-place-minded plan, okay? And then you can get that in like a task tag form, for example, send that bitch to your Google Docs, okay? You have small fucking steps in that thing, right? Well, you know, you can have that associated directly with your calendar, for example, you can get reminders sent to you, okay? You could have a state of this test updated as you complete these things, you can mutate the state of the task tag in that and that mutation would propagate it, which is the Google Doc, so which is the reminders you have sent to you for example, right? And that's really just the tip of the iceberg, okay, but that's like the alpha in our pre-MVP idea.